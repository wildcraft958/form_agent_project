import os
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_ollama import ChatOllama
from dotenv import load_dotenv

load_dotenv()


class LLMHandler:
    def __init__(self, model_type="huggingface", history_manager=None):
        """
        Initialize the LLM handler.
        
        Args:
            model_type (str): Type of model to use - "ollama" or "huggingface"
            history_manager: Instance of ChatHistoryManager for tracking conversation
        """
        self.model_type = model_type
        self.history_manager = history_manager
        self.llm = self._initialize_llm()
        
    def _initialize_llm(self):
        """
        Initialize the appropriate LLM based on the model type.
        
        Returns:
            LLM: The initialized language model
        """
        if self.model_type == "ollama":
            # Initialize Ollama
            return ChatOllama(model="llama3")
            
        elif self.model_type == "huggingface":
            # Initialize Hugging Face model
            from langchain_community.llms import HuggingFaceHub
            hf_api_key = os.getenv("HUGGINGFACE_API_KEY")
            return HuggingFaceHub(
                repo_id="ruslanmv/Medical-Llama3-8B",
                huggingfacehub_api_token=hf_api_key
            )
        else:
            raise ValueError(f"Unsupported model type: {self.model_type}")
    
    def create_system_prompt(self, form_data):
        """
        Create a system prompt for the LLM based on the form data.
        
        Args:
            form_data (dict): The JSON representation of the form
            
        Returns:
            str: The system prompt
        """
        # Build a description of the form fields
        form_description = "You are an AI assistant helping fill out a medical form. The form has the following fields:\n\n"
        
        for field_name, field_info in form_data.items():
            field_label = field_info.get('label', field_name)
            field_type = field_info.get('type', 'text')
            form_description += f"- {field_label} (Field name: {field_name}, Type: {field_type})\n"
        
        # Add instructions for the LLM
        form_description += "\nPlease fill out this form with appropriate medical information. "
        form_description += "Be concise, accurate, and professional. Provide realistic values for each field."
        
        return form_description
    
    def process_form(self, form_data, user_query=None):
        """
        Process the form using the LLM.
        
        Args:
            form_data (dict): The JSON representation of the form
            user_query (str, optional): Additional user query
            
        Returns:
            dict: Filled form with values generated by the LLM
        """
        # Create system prompt
        system_prompt = self.create_system_prompt(form_data)
        
        # Get chat history if available
        chat_history = ""
        if self.history_manager:
            chat_history = self.history_manager.get_formatted_history()
        
        # Create the prompt template
        template = """
        {system_prompt}
        
        {chat_history}
        
        Form to fill:
        {form_description}
        
        {user_query}
        
        Please fill out the form with appropriate values for each field.
        """
        
        prompt = PromptTemplate(
            input_variables=["system_prompt", "chat_history", "form_description", "user_query"],
            template=template
        )
        
        # Create a description of the form
        form_description = ""
        for field_name, field_info in form_data.items():
            field_label = field_info.get('label', field_name)
            form_description += f"{field_label}: [FILL THIS]\n"
        
        # Set default user query if not provided
        if not user_query:
            user_query = "Please fill out this medical form with appropriate information."
        
            chain = (
                RunnablePassthrough.assign(
                    system_prompt=lambda x: x["system_prompt"],
                    chat_history=lambda x: x["chat_history"]
                )
                | prompt
                | self.llm
                | StrOutputParser()
            )
        
        response = chain.invoke({
            "system_prompt": system_prompt,
            "chat_history": chat_history,
            "form_description": form_description,
            "user_query": user_query
        })
                
        # Parse the response and update form values
        filled_form = self._parse_llm_response(form_data, response)
        
        # Update chat history
        if self.history_manager:
            self.history_manager.add_to_history("user", user_query)
            self.history_manager.add_to_history("assistant", response)
        
        return filled_form
    
    def _parse_llm_response(self, form_data, response):
        """
        Parse the LLM response and extract values for form fields.
        
        Args:
            form_data (dict): The original form data
            response (str): The LLM response
            
        Returns:
            dict: Updated form data with values from LLM
        """
        # Create a copy of the form data to update
        filled_form = form_data.copy()
        
        # Split response by lines
        lines = response.strip().split('\n')
        
        # Process each line
        for line in lines:
            # Look for field_label: value pattern
            if ':' in line:
                parts = line.split(':', 1)
                field_label = parts[0].strip()
                field_value = parts[1].strip()
                
                # Find matching field by label
                for field_name, field_info in form_data.items():
                    if field_info.get('label', field_name) == field_label:
                        # Update the value
                        filled_form[field_name]['value'] = field_value
                        break
        
        return filled_form
